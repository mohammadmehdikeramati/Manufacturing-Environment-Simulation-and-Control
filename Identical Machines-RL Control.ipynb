{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and constants are defined correctly.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simpy\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import math\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='manufacturing_RC_env9.log', level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s', filemode='w')\n",
    "\n",
    "\n",
    "# Constants and assumptions\n",
    "NUM_MACHINES = 6\n",
    "BUFFER_CAPACITY = 10\n",
    "MEAN_PROCESSING_TIME = 83.70\n",
    "MEAN_STARTUP_TIME = 30\n",
    "MTBF = 3600\n",
    "MTTR = 30\n",
    "MEAN_PART_ARRIVAL_TIME = 20\n",
    "\n",
    "\n",
    "# Power consumption for each state (in kW)\n",
    "POWER_STANDBY = 0.1\n",
    "POWER_IDLE = 9.3\n",
    "POWER_STARTUP = 10\n",
    "POWER_BUSY = 15\n",
    "POWER_FAILED = 0.1\n",
    "\n",
    "\n",
    "# Power consumption rates (kW)\n",
    "POWER_CONSUMPTION = {\n",
    "    'busy': 15,\n",
    "    'idle': 9,\n",
    "    'startup': 10,\n",
    "    'standby': 0,\n",
    "    'failed': 0\n",
    "}\n",
    "\n",
    "print(\"Imports and constants are defined correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManufacturingEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(ManufacturingEnv, self).__init__()\n",
    "\n",
    "\n",
    "      \n",
    "        self.action_space = gym.spaces.Discrete(NUM_MACHINES + 1) ###############\n",
    "        #self.observation_space = gym.spaces.MultiDiscrete([BUFFER_CAPACITY + 1] + [5] * NUM_MACHINES) ##########################\n",
    "        #low = np.array([0] * (NUM_MACHINES + 2), dtype=np.float32)  # Minimum values\n",
    "        #high = np.array([BUFFER_CAPACITY] + [4] * NUM_MACHINES + [np.inf], dtype=np.float32)  # Maximum values\n",
    "        #self.observation_space = gym.spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Box(low=np.zeros(8), high=np.inf * np.ones(8))\n",
    "\n",
    "\n",
    "\n",
    "        self.env = simpy.Environment()\n",
    "        self.buffer = simpy.Store(self.env, capacity=BUFFER_CAPACITY)\n",
    "        self.max_parts = 0\n",
    "        self.produced_parts=0\n",
    "        self.Capacity=0 \n",
    "        self.data=[]\n",
    "        self.CC=0\n",
    "        self.machines_energy=[0]\n",
    "        self.energy=0\n",
    "        self.AON_produced=0\n",
    "        self.produced=0\n",
    "\n",
    "        self.machines = [{\n",
    "            'id': i,\n",
    "            'state': 'standby',  # Start machines in standby state\n",
    "            'total_energy': 0,\n",
    "            'time_in_states': {'busy': 0, 'idle': 0, 'startup': 0, 'standby': 0, 'failed': 0}, \n",
    "            'cumprocessingtime': 0, 'state_energy_consumption':0,\n",
    "            'failuretime': random.expovariate(1.0 / MTBF)\n",
    "        } for i in range(NUM_MACHINES)]\n",
    "\n",
    "    \n",
    "    def collect_data(self, machine):\n",
    "       \n",
    "     state_energy = 0\n",
    "     for state, time in machine['time_in_states'].items():\n",
    "        time_hours=0\n",
    "        if state==machine['state']:\n",
    "          time_hours = time\n",
    "          time_hours=time_hours\n",
    "          state_energy += POWER_CONSUMPTION[state] * time_hours\n",
    "          self.data.append({\n",
    "         'time': self.env.now,\n",
    "         'machine_id': machine['id'],\n",
    "         'state': machine['state'],\n",
    "         'time_in_preocess': time_hours,'state_energy':machine['state_energy_consumption'],\n",
    "         'total_state_energy':state_energy})\n",
    "\n",
    "\n",
    "    def process(self, machine):\n",
    "\n",
    "        yield self.env.timeout(1)\n",
    "     \n",
    "        while True:\n",
    "\n",
    "            logging.info(f'-------------------- Process just started --------------------------')\n",
    "            logging.info(f'env time: {self.env.now}, machine id {machine['id']} is {machine['state']}')\n",
    "            processing_time = random.expovariate(1.0 / MEAN_PROCESSING_TIME)\n",
    "            #failure_time = random.expovariate(1.0 / MTBF) \n",
    "\n",
    "            if machine['state'] == 'idle':\n",
    "\n",
    "                machine['time_in_states']['idle'] = 0.99 \n",
    "\n",
    "                #if self.CC==0:  \n",
    "                     \n",
    "                machine['state_energy_consumption']= POWER_CONSUMPTION['idle']\n",
    "                self.collect_data(machine)\n",
    "                  \n",
    "                yield self.env.timeout(0.99)\n",
    "\n",
    "            elif machine['state'] == 'standby':\n",
    "\n",
    "                machine['time_in_states']['standby'] = 0.99\n",
    "\n",
    "                #if self.CC==0:\n",
    "                 \n",
    "                machine['state_energy_consumption']= POWER_CONSUMPTION['standby']\n",
    "                self.collect_data(machine)\n",
    "\n",
    "                yield self.env.timeout(0.99)               \n",
    "\n",
    "            elif machine['state']=='startup':\n",
    "                \n",
    "                startup_time=random.expovariate(1.0 /MEAN_STARTUP_TIME)\n",
    "                machine['time_in_states']['startup'] = startup_time\n",
    "                machine['state_energy_consumption']=POWER_CONSUMPTION['startup']\n",
    "                self.collect_data(machine)\n",
    "\n",
    "                yield self.env.timeout(startup_time) \n",
    "                machine['state'] = 'busy'\n",
    "\n",
    "#########################################################################################################################################################\n",
    "            elif machine['state'] == 'busy':\n",
    "\n",
    "                if machine['cumprocessingtime']+processing_time <= machine['failuretime']:\n",
    "                    machine['cumprocessingtime']=processing_time+machine['cumprocessingtime']\n",
    "                    machine['time_in_states']['busy'] = processing_time\n",
    "\n",
    "                    machine['state_energy_consumption']=POWER_CONSUMPTION['busy'] ###################################################\n",
    "                    \n",
    "                    yield self.buffer.get()\n",
    "\n",
    "                    self.produced_parts=self.max_parts- len(self.buffer.items)\n",
    "                    self.produced=self.produced+1 \n",
    "                    \n",
    "                    self.collect_data(machine)\n",
    "\n",
    "                    yield self.env.timeout(processing_time)\n",
    "                    machine['state'] = 'idle'\n",
    "\n",
    "                else:\n",
    "                    failure_time_remaining = machine['failuretime'] - machine['cumprocessingtime']\n",
    "                    machine['time_in_states']['busy'] = failure_time_remaining\n",
    "\n",
    "                    machine['state_energy_consumption']=POWER_CONSUMPTION['busy'] ############################################\n",
    "\n",
    "                    yield self.buffer.get() \n",
    "########################################################################################################################################################\n",
    "                    \n",
    "                    machine['cumprocessingtime']=0\n",
    "                    self.collect_data(machine)\n",
    "\n",
    "                    yield self.env.timeout(failure_time_remaining)\n",
    "                    machine['state'] = 'failed'\n",
    "\n",
    "                    repair_time = random.expovariate(1.0 / MTTR)\n",
    "                    machine['time_in_states']['failed'] = repair_time \n",
    "                    yield self.env.timeout(repair_time)\n",
    "                    self.collect_data(machine)\n",
    "                    machine['state'] ='idle'\n",
    "        \n",
    "\n",
    "    def part_arrival(self):\n",
    "\n",
    "        yield self.env.timeout(1)\n",
    "\n",
    "        while True:\n",
    "          \n",
    "          if len(self.buffer.items)<BUFFER_CAPACITY:\n",
    "             yield self.env.timeout(np.random.exponential(MEAN_PART_ARRIVAL_TIME))\n",
    "             logging.info(f'Part just arrived, env time: {self.env.now}')\n",
    "             yield self.buffer.put(f\"{self.env.now}\") \n",
    "             self.produced_parts=0\n",
    "             self.Capacity= self.Capacity+1\n",
    "             self.max_parts = len(self.buffer.items)\n",
    "             self.AON_produced=self.AON_produced+1\n",
    "\n",
    "          else:\n",
    "           self.max_parts = len(self.buffer.items)\n",
    "           yield self.env.timeout(1)\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "    def get_available_machines(self): ############################################################\n",
    "        # Count the number of machines that are in a state where they can be turned on\n",
    "        available_machines = 0\n",
    "        for machine in self.machines:\n",
    "            if machine['state'] in ['idle', 'standby']:  # Machines that can be turned on\n",
    "                available_machines += 1\n",
    "        return available_machines\n",
    "\n",
    "    def adjust_action_space(self): ##############################################################\n",
    "        # Get the number of available machines\n",
    "        available_machines = self.get_available_machines()\n",
    "\n",
    "        # Limit the action space to the number of available machines\n",
    "        self.action_space = gym.spaces.Discrete(available_machines + 1)  # +1 to include the \"do nothing\" action\n",
    "        logging.info(f'permited actions: {self.action_space}, env time: {self.env.now}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "              \n",
    "               \n",
    "              \n",
    "              if self.env.now>=1:\n",
    "\n",
    "               logging.info(f'------------------- Control just activated ---------------------------')\n",
    "               logging.info(f'permited action {self.action_space} and action: {action}, env time: {self.env.now}, buffer:{len(self.buffer.items)}')\n",
    "            \n",
    "\n",
    "               self.adjust_action_space() ##################################################################\n",
    "               # Execute the action in the environment\n",
    "               self.actions_controller(action)\n",
    "        \n",
    "              # Advance the simulation by a fixed time step (e.g., 1 time unit)\n",
    "              self.env.run(until=self.env.now + 1)\n",
    "\n",
    "              logging.info(f'-------------------------------------------------- Environment: {self.env.now}--------------------------------------------------------')\n",
    "              \n",
    "              logging.info(f'--------------------- Observations -------------------------')\n",
    "              observation=self.get_state()\n",
    "              current_machines_energy=observation[-1]\n",
    "\n",
    "              self.machines_energy.append(current_machines_energy)\n",
    "              current_machines_energy= self.machines_energy[-1]\n",
    "              previous_machines_energy= self.machines_energy[-2]\n",
    "              total_reward=self.calculate_reward(current_machines_energy, previous_machines_energy)\n",
    "\n",
    "              logging.info(f'state info before control: {observation}, env time: {self.env.now}')\n",
    "              logging.info(f'----------------------------------------------')\n",
    "\n",
    "              done = self.env.now >= 10000  # Define a condition to terminate the episode\n",
    "              truncated=False \n",
    "              \n",
    "\n",
    "              #print('states are', observation, 'should be', self.observation_space, 'action', self.action_space)\n",
    "              return observation, total_reward, done, truncated, {}\n",
    "                           \n",
    " \n",
    "    def actions_controller(self, action):\n",
    "\n",
    "        active_machines = action\n",
    "        self.CC=0\n",
    "       \n",
    "        for machine in self.machines:\n",
    "            \n",
    "            logging.info(f'Machine under investigation: {machine[\"id\"]} and the state {machine[\"state\"]}, env time: {self.env.now}, capacity: {self.Capacity}')\n",
    "            \n",
    "            #if machine['state'] == 'idle' and active_machines > 0 and self.Capacity>0:\n",
    "            if machine['state'] == 'idle' and active_machines > 0 : \n",
    "                self.CC=1\n",
    "                machine['state'] = 'busy'\n",
    "                active_machines -= 1\n",
    "                self.Capacity -= 1\n",
    "                logging.info(f\"Machine id {machine['id']} mode changed from idle to {machine['state']}, actions left: {active_machines}, env time: {self.env.now}\")\n",
    "            \n",
    "            #elif machine['state'] == 'idle' and active_machines > 0 and self.Capacity==0: \n",
    "                #self.CC=1\n",
    "                #machine['state'] = 'standby'\n",
    "                #logging.info(f\"Machine id {machine['id']} mode changed from idle to {machine['state']}, actions left: {active_machines}, env time: {self.env.now}\")\n",
    "                \n",
    "            elif machine['state'] == 'idle' and active_machines == 0:\n",
    "                self.CC=1\n",
    "                machine['state'] = 'standby'\n",
    "                logging.info(f\"Machine id {machine['id']} mode changed from idle to {machine['state']}, actions left: {active_machines}, env time: {self.env.now}\") \n",
    "\n",
    "            #elif machine['state'] == 'standby' and active_machines > 0 and self.Capacity>0:\n",
    "            elif machine['state'] == 'standby' and active_machines > 0 :\n",
    "                self.CC=1\n",
    "                machine['state'] = 'startup'\n",
    "                active_machines -= 1\n",
    "                self.Capacity -= 1\n",
    "                logging.info(f\"Machine id {machine['id']} mode changed from standby to {machine['state']}, actions left: {active_machines}, env time: {self.env.now}\")\n",
    "\n",
    "        #return self.get_state()\n",
    "        \n",
    "\n",
    "\n",
    "    def get_state(self):\n",
    "\n",
    "        parts_in_buffer = len(self.buffer.items)\n",
    "\n",
    "        self.energy=0\n",
    "\n",
    "        for machine in self.machines:\n",
    "          \n",
    "          #logging.info(f\"''''''''''''''''''''''''''Energy consumption in get state function''''''''''''''''''''''''''''''''''''''', env: {self.env.now}\")\n",
    "          \n",
    "          #logging.info(f\"energy consumption of machine id {machine['id']} is {machine['total_energy']}, env time: {self.env.now}\")\n",
    "          self.energy += machine['total_energy'] \n",
    "\n",
    "        logging.info(f\"total energy consumption {self.energy}, env time: {self.env.now}\")\n",
    "\n",
    "        state_mapping = {'idle': 0, 'busy': 1, 'startup': 2, 'standby': 3, 'failed': 4} ############################################\n",
    "        machine_states = [state_mapping[machine['state']] for machine in self.machines]\n",
    "        observation = np.array([parts_in_buffer] + machine_states + [self.energy])\n",
    "\n",
    "        return observation\n",
    "        \n",
    "    \n",
    "    def consumption_calculation(self):\n",
    "\n",
    "        yield self.env.timeout(1)\n",
    "\n",
    "        while True:\n",
    "         \n",
    "         if self.env.now>1:\n",
    "         \n",
    "          logging.info(f\"---------------Energy consumption calculation just started---------------\")\n",
    "         \n",
    "          for machine in self.machines:\n",
    "            machine['total_energy']=machine['total_energy']+machine['state_energy_consumption']\n",
    "\n",
    "            logging.info(f\"energy consumption of machine id {machine['id']} is {machine['total_energy']}, env time: {self.env.now}\")\n",
    "\n",
    "         yield self.env.timeout(0.99)\n",
    "\n",
    "\n",
    "    def calculate_reward(self, current_machines_energy, previous_machines_energy):\n",
    "\n",
    "        logging.info(f\"produced parts {self.produced}, max_parts {self.AON_produced}\")\n",
    "        productivity_reward = np.exp((self.produced) / (self.AON_produced+0.000000001))/math.e\n",
    "        consumption_reward = np.exp(-0.01*(current_machines_energy -(previous_machines_energy+0.000000001 ))) \n",
    "        total_reward = 0* productivity_reward + consumption_reward\n",
    "        logging.info(f\"consumption reward is {consumption_reward},productivity reward is {productivity_reward}, total reward is {total_reward}, env time: {self.env.now}\")\n",
    "\n",
    "        return total_reward\n",
    "\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "\n",
    "        if seed is not None: \n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "\n",
    "        # Reinitialize all environment variables\n",
    "        self.env = simpy.Environment()\n",
    "        self.buffer = simpy.Store(self.env, capacity=BUFFER_CAPACITY)\n",
    "        self.machines_energy = [0]\n",
    "        self.produced_parts = 0\n",
    "        self.Capacity = 0\n",
    "        self.data = []\n",
    "        self.CC = 0\n",
    "        self.AON_produced = 0\n",
    "        self.produced = 0\n",
    "        # Reinitialize the machines\n",
    "        self.machines = [{\n",
    "            'id': i,\n",
    "            'state': 'idle',\n",
    "            'total_energy': 0,\n",
    "            'time_in_states': {'busy': 0, 'idle': 0, 'startup': 0, 'standby': 0, 'failed': 0},\n",
    "            'cumprocessingtime': 0, 'state_energy_consumption': 0,\n",
    "            'failuretime': random.expovariate(1.0 / MTBF)\n",
    "        } for i in range(NUM_MACHINES)]\n",
    "        # Restart the processes\n",
    "        for machine in self.machines:\n",
    "            self.env.process(self.process(machine))\n",
    "        self.env.process(self.part_arrival())\n",
    "        self.env.process(self.consumption_calculation())\n",
    "        # Return the initial state\n",
    "        initial_state= self.get_state()\n",
    "\n",
    "        info={} \n",
    "    \n",
    "\n",
    "        return initial_state, info\n",
    "\n",
    "    @staticmethod\n",
    "    def LogHandel():\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            handler.close()\n",
    "            logging.root.removeHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Create the environment (wrapped in DummyVecEnv for stable_baselines3 compatibility)\n",
    "MEnv = ManufacturingEnv()\n",
    "ENV = DummyVecEnv([lambda: MEnv])\n",
    "\n",
    "# Create the DQN model\n",
    "dqn_model = DQN(\"MlpPolicy\", ENV, ######################################################\n",
    "                verbose=1, learning_rate=0.001, buffer_size=10000, learning_starts=1000, \n",
    "                batch_size=32, gamma=0.99, target_update_interval=500, exploration_fraction=0.1, \n",
    "                exploration_final_eps=0.01, train_freq=4, gradient_steps=1)\n",
    "\n",
    "# Train the model\n",
    "dqn_model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the model\n",
    "dqn_model.save(\"dqn_manufacturing_env\")\n",
    "\n",
    "# Load the trained model (optional, for testing later)\n",
    "dqn_model = DQN.load(\"dqn_manufacturing_env\")\n",
    "\n",
    "# Test the trained model\n",
    "obs = MEnv.reset()\n",
    "\n",
    "action = random.randint(0, NUM_MACHINES)\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "\n",
    "    obs, reward, done, truncated, x= MEnv.step(action)\n",
    "    logging.info(f\"Observations {obs}, reward {reward}, env {MEnv.env.now}\")\n",
    "    #print(f\"Action: {action}, Reward: {reward}, Done: {done}, env {MEnv.env.now}\", )\n",
    "\n",
    "    action, _states = dqn_model.predict(obs, deterministic=True)  # Use the trained model to predict actions\n",
    "    logging.info(f\"Predicted actions {action}, env {MEnv.env.now}\") \n",
    "    obs, reward, done, truncated, info = ENV.step(action)\n",
    "\n",
    "# Data collection\n",
    "Data = pd.DataFrame(MEnv.data)\n",
    "Data.to_excel(\"Data.xlsx\", sheet_name=\"Data\", index=False)\n",
    "\n",
    "# Log handler\n",
    "MEnv.LogHandel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
